{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots figure 5 supplementary figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "import skimage\n",
    "import plotnine as pn\n",
    "\n",
    "import colicycle.tools_GW as tgw\n",
    "import colicycle.time_mat_operations as tmo\n",
    "import colicycle.decomposition as dc\n",
    "\n",
    "import tabulate\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning function\n",
    "def windowing(dataframe, variable, step):\n",
    "    minval = dataframe[variable].min()\n",
    "    maxval = dataframe[variable].max()\n",
    "    bin_np, bin_pos = np.histogram(dataframe[variable].dropna(),bins = np.arange(minval,maxval,step))\n",
    "    newbins = [0.5*(bin_pos[x]+bin_pos[x+1]) for x in range(len(bin_pos)-1)]\n",
    "    minpos = bin_pos[np.where(bin_np>10)[0][0]]\n",
    "    maxpos = bin_pos[np.where(bin_np>10)[0][-1]]\n",
    "    subdata = dataframe[(dataframe[variable]>minpos)&(dataframe[variable]<maxpos)]\n",
    "\n",
    "    which_bin = np.digitize(subdata[variable],bins = np.arange(0,10,0.05))\n",
    "    grouped = [subdata.iloc[which_bin==x] for x in np.sort(np.unique(which_bin))]\n",
    "    return grouped\n",
    "\n",
    "#renaming function for plotting purposes\n",
    "def renaming(name):\n",
    "    \n",
    "    name = [x.replace('tau_fit','$\\\\\\\\lambda$') if type(x)==str else x for x in name]\n",
    "    name = [x.replace('Li_fit','$L_i\\ [\\mu m]$') if type(x)==str else x for x in name]\n",
    "    name = [x.replace('Ld_fit','$L_d\\ [\\mu m]$') if type(x)==str else x for x in name]\n",
    "    name = [x.replace('Lb_fit','$L_b\\ [\\mu m]$') if type(x)==str else x for x in name]\n",
    "    name = [re.sub(r'\\bTi\\b', '$T_{bi}$', x) if type(x)==str else x for x in name]\n",
    "    name = [x.replace('Td','$T_{bd}$') if type(x)==str else x for x in name]\n",
    "    #name = [re.sub(r'\\bfinal_DLdLi\\b', '$d\\\\\\\\Lambda_{ib}\\ [\\\\\\\\mu m]$', x) if type(x)==str else x for x in name]\n",
    "    name = [re.sub(r'\\bDLdLi\\b', '$d\\\\\\\\Lambda_{ib}\\ [\\\\\\\\mu m]$', x) if type(x)==str else x for x in name]\n",
    "    name = [re.sub(r'\\DLi\\b', '$d\\\\\\\\Lambda_{if}\\ [\\\\\\\\mu m]$', x) if type(x)==str else x for x in name]\n",
    "    \n",
    "    #name = [re.sub(r'\\bDeltaLid\\b', '$dL_{id}\\ [\\\\\\\\mu m]$', x) if type(x)==str else x for x in name]\n",
    "    name = [re.sub(r'\\bnumori_born\\b', 'Num. origins at birth', x) if type(x)==str else x for x in name]\n",
    "    name = [x.replace('DeltaTid','$T_{id}$') if type(x)==str else x for x in name]\n",
    "    name = [x.replace('DeltaL','$dL\\ [\\mu m]$') if type(x)==str else x for x in name]\n",
    "    name = [x.replace('rLdLb','$R_{db}$') if type(x)==str else x for x in name]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define folder containing the PreProcess folder\n",
    "main_folder = '../'\n",
    "\n",
    "#create a dictionary entry per condition to analyse.\n",
    "#Give data location, period to consider, condition name for legends, simulation type, final figure name \n",
    "#and a reference name for the condition (used when producing simulation data)\n",
    "datasource = {'glycerolauto': {'datafile': main_folder+'PreProcessed/20170327_GW339_temp/colidata.pkl',\n",
    "                                'period': 1, 'condition': 'Glycerol (auto)','sim_type':'standard',\n",
    "                              'fig_names':'fig5_sup1.pdf','condid':'glycerolauto'},\n",
    "              'glycerol': {'datafile':main_folder+'PreProcessed/20180706_GW296_glycerol37_1_MMStack/colidata.pkl',\n",
    "                          'period': 0, 'condition' : 'Glycerol','sim_type':'standard',\n",
    "                          'fig_names':'fig5_sup2.pdf','condid':'glycerol'},\n",
    "              'glucose': {'datafile': main_folder+'PreProcessed/20180711_GW296_glucose37_1_MMStack/colidata.pkl',\n",
    "                          'period': 0, 'condition' : 'Glucose','sim_type':'standard',\n",
    "                         'fig_names':'fig5_sup3.pdf','condid':'glucose'},\n",
    "              'glucose8aa': {'datafile': main_folder+'PreProcessed/20180709_GW296_glucose8aa37_1_MMStack/colidata.pkl',\n",
    "                          'period': 0, 'condition' : 'Glucose 8aa','sim_type':'standard',\n",
    "                            'fig_names':'fig5_sup4.pdf','condid':'glucose8aa'},\n",
    "             'glycerolauto2': {'datafile': main_folder+'PreProcessed/20170327_GW339_temp/colidata.pkl',\n",
    "                                'period': 1, 'condition': 'Glycerol (auto)','sim_type':'classicadder',\n",
    "                             'fig_names':'fig_app2_2.pdf','condid':'glycerolauto'}}\n",
    "\n",
    "#define folder containing simulation data\n",
    "simulation_source = main_folder+'DataSimulations/'\n",
    "\n",
    "#define folder where to save plots\n",
    "tosave_folder = main_folder+'Plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This large cells plots each individual plot of the Supplementary figure to figure 5 and in the end assembles them into a single large figure.\n",
    "\n",
    "do_scatter, do_histo etc. allow one to choose which plots to (re-)create. Then the loop goes through the dictionary defined above and creates a figure per entry (plus the individual figures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_xpos = 0.68\n",
    "fontsize = 25\n",
    "\n",
    "do_scatter = True\n",
    "do_histo = True\n",
    "do_ori = True\n",
    "do_assembly = True\n",
    "\n",
    "#go through all conditions/data types\n",
    "for d in datasource:\n",
    "    cond = datasource[d]['condid']\n",
    "    simtype = datasource[d]['sim_type']\n",
    "    figname = datasource[d]['fig_names']\n",
    "    \n",
    "    #######load and format data######\n",
    "    datafile = datasource[d]['datafile']\n",
    "    #load experimental data\n",
    "    expinfo = {}\n",
    "    expinfo['size_scale'] = 65#nm/px\n",
    "    expinfo['time_scale'] = 3#in min\n",
    "\n",
    "    colidata = pd.read_pickle(datafile)\n",
    "    colidata = colidata[colidata.period==datasource[d]['period']]\n",
    "\n",
    "    #scale lengths in microns\n",
    "    colidata[['DLi','Lb_fit','Ld_fit','Ld','Lb','Ld','Li','Li_fit','Li_old']] \\\n",
    "    =colidata[['DLi','Lb_fit','Ld_fit','Ld','Lb','Ld','Li','Li_fit','Li_old']].applymap(lambda x: x*expinfo['size_scale']/1000)\n",
    "\n",
    "    colidata['DeltaL'] = colidata.Ld_fit-colidata.Lb_fit\n",
    "\n",
    "    #keep only good data\n",
    "    colidata = colidata[colidata.pearson_log>0.95]\n",
    "    colidata = colidata[colidata.tau_fit>0]\n",
    "\n",
    "    colidata['DLdLi'] = colidata.Ld_fit-colidata.Li_fit\n",
    "    colidata['final_DLdLi']  = colidata['DLdLi']\n",
    "\n",
    "\n",
    "    #load simulation data and complete dataframe\n",
    "    simul_file = simulation_source+cond+'_'+simtype+'.pkl'\n",
    "\n",
    "    colisimul = pd.read_pickle(simul_file)\n",
    "\n",
    "\n",
    "    colisimul['DeltaL'] = colisimul.Ld_fit-colisimul.Lb_fit\n",
    "    colidata['numori_born'] = colidata.Ti.apply(lambda x: 1 if x>=0 else 2)\n",
    "    colisimul['DLdLi'] = colisimul.Ld_fit-colisimul.Li_fit\n",
    "\n",
    "\n",
    "    #create average binned data\n",
    "    group_Lb_simul = windowing(colisimul,'Lb_fit',0.05)\n",
    "    group_Lb_exp = windowing(colidata,'Lb_fit',0.05)\n",
    "\n",
    "    group_Li_simul = windowing(colisimul,'Li_fit',0.05)\n",
    "    group_Li_exp = windowing(colidata,'Li_fit',0.05)\n",
    "\n",
    "    #list of used variables\n",
    "    varlist = ['Lb_fit','Ld_fit','DLi','DLdLi','DeltaL']\n",
    "\n",
    "    #list of pairs of variables used in correlation plots\n",
    "    varpairs = [['Lb_fit','Li_fit',group_Lb_exp, group_Lb_simul],['Li_fit','DLdLi', group_Li_exp, group_Li_simul],\n",
    "                ['Lb_fit','DeltaL', group_Lb_exp, group_Lb_simul]]\n",
    "\n",
    "    #Assigning legend name for data types\n",
    "    colisimul['datatype'] = 'Simulations'\n",
    "    colidata['datatype'] = 'Experiments'\n",
    "\n",
    "    #assembling experimental and simulation data\n",
    "    coli = pd.concat([colisimul,colidata],sort=False)\n",
    "\n",
    "    plot_count = 0\n",
    "\n",
    "    ########plot binned scatter plots###########\n",
    "    if do_scatter:\n",
    "        for v in varpairs:\n",
    "            df = pd.DataFrame({'len':[len(x) for x in v[2]]/np.sum([len(x) for x in v[2]]),\n",
    "                               v[0]:[x[v[0]].mean() for x in v[2]],\n",
    "                               v[1]:[x[v[1]].mean() for x in v[2]],\n",
    "                              v[1]+'std1':[x[v[1]].mean()+x[v[1]].sem() for x in v[2]],\n",
    "                              v[1]+'std2':[x[v[1]].mean()-x[v[1]].sem() for x in v[2]],\n",
    "                              'datatype':'Experiments'})\n",
    "            df_s = pd.DataFrame({'len':[len(x) for x in v[3]]/np.sum([len(x) for x in v[3]]),\n",
    "                               v[0]:[x[v[0]].mean() for x in v[3]],\n",
    "                               v[1]:[x[v[1]].mean() for x in v[3]],\n",
    "                                 v[1]+'std1':[x[v[1]].mean()+x[v[1]].sem() for x in v[3]],\n",
    "                              v[1]+'std2':[x[v[1]].mean()-x[v[1]].sem() for x in v[3]],\n",
    "                                'datatype':'Simulations'})\n",
    "            df = pd.concat([df,df_s])\n",
    "            \n",
    "\n",
    "            p = (pn.ggplot()\n",
    "             + pn.geom_point(pn.aes(x=v[0], y=v[1],alpha ='len', color = 'datatype'),data= df, size = 3)\n",
    "             + pn.geom_errorbar(pn.aes(x=v[0], ymin = v[1]+'std1', ymax = v[1]+'std2',alpha ='len', color = 'datatype'), data= df, width = 0.02)\n",
    "             + pn.xlab(renaming([v[0]])[0])\n",
    "             + pn.ylab(renaming([v[1]])[0])\n",
    "            +pn.coord_cartesian(ylim = (np.min(df[v[1]])-0.5,np.max(df[v[1]])+1))\n",
    "             #+ pn.ggtitle('Greek Letter Analysis')\n",
    "             +pn.theme_bw(base_size = 20)\n",
    "             + pn.theme(legend_position=(leg_xpos, 0.8),legend_key = pn.element_rect(colour = [1,1,1,1], fill = \"white\"),\n",
    "                        legend_background = pn.element_rect(fill = [1,0,0,0]),\n",
    "                       text=pn.element_text(size=25))\n",
    "             +pn.scale_colour_manual(values=['red','blue'],name=' ')\n",
    "             +pn.guides(alpha=False)\n",
    "             #+ pn.scale_color_discrete(name='name')\n",
    "            )\n",
    "            print(p)\n",
    "            pn.ggplot.save(p,tosave_folder+'fig5sup/'+cond+'_'+simtype+'_'+str(plot_count)+'.png',dpi=600)\n",
    "            plot_count += 1\n",
    "    else:\n",
    "        plot_count += 3\n",
    "\n",
    "    ########plot hisrograms###########\n",
    "    if do_histo:\n",
    "        for vval in varlist:\n",
    "            padding = 1.5 if (vval == 'DLi')|(vval == 'DeltaL') else 0.5\n",
    "            p = (pn.ggplot(coli,pn.aes(x=vval,fill = 'datatype'))\n",
    "            #+pn.stat_bin(y = 'density','position' = 'stack')\n",
    "             + pn.geom_histogram(pn.aes(y='stat(density)'),position = 'identity',alpha = 0.5)\n",
    "             + pn.theme_bw(base_size = 20)\n",
    "             + pn.theme(legend_position=(leg_xpos, 0.8),legend_key = pn.element_rect(colour = [1,1,1,1], fill = \"white\"),\n",
    "                        legend_background = pn.element_rect(fill = [1,0,0,0]),\n",
    "                       text=pn.element_text(size=25))\n",
    "             + pn.coord_cartesian(xlim = (np.min(coli[vval])-0.5,np.max(coli[vval])+padding))\n",
    "             + pn.scale_fill_manual(values=['red','blue'],name=' ')\n",
    "             + pn.guides(alpha=False)\n",
    "             + pn.xlab(renaming([vval])[0])\n",
    "             + pn.ylab(' ')\n",
    "               )\n",
    "            print(p)\n",
    "            pn.ggplot.save(p,tosave_folder+'fig5sup/'+cond+'_'+simtype+'_'+str(plot_count)+'.png',dpi=600)\n",
    "            plot_count += 1\n",
    "    else:\n",
    "        plot_count += 5\n",
    "\n",
    "    ###########plot origins distributions############\n",
    "    if do_ori:\n",
    "        or_exp = coli[coli.datatype == 'Experiments'].groupby('numori_born').size()\n",
    "        or_simul = coli[coli.datatype == 'Simulations'].groupby('numori_born').size()\n",
    "\n",
    "        or_exp = or_exp/np.sum(or_exp)\n",
    "        or_simul = or_simul/np.sum(or_simul)\n",
    "\n",
    "        origins = pd.DataFrame({'Simulations':or_simul,'Experiments':or_exp})\n",
    "        origins = origins.reset_index()\n",
    "        origins = pd.melt(origins, value_vars=['Simulations','Experiments'],id_vars='numori_born')\n",
    "\n",
    "\n",
    "        p = (pn.ggplot(origins, pn.aes(x = 'numori_born',y='value', fill='variable'))\n",
    "             + pn.geom_col(position=\"dodge\", width = 0.3)\n",
    "             + pn.theme_bw(base_size = 20)\n",
    "             + pn.theme(legend_position=(leg_xpos, 0.8),legend_key = pn.element_rect(colour = [1,1,1,1], fill = \"white\"),\n",
    "                        legend_background = pn.element_rect(fill = [1,0,0,0]),\n",
    "                       text=pn.element_text(size=25))\n",
    "             + pn.scale_fill_manual(values=['red','blue'],name=' ')\n",
    "             + pn.coord_cartesian(xlim = (0.5,4.5))\n",
    "             + pn.guides(alpha=False)\n",
    "             + pn.xlab('Num. origins at birth')\n",
    "             + pn.ylab(' '))\n",
    "        print(p)\n",
    "        pn.ggplot.save(p,tosave_folder+'fig5sup/'+cond+'_'+simtype+'_'+str(plot_count)+'.png',dpi=600)\n",
    "\n",
    "\n",
    "    ############assemble plots#################\n",
    "    if do_assembly:\n",
    "        X,Y = np.meshgrid(np.arange(3),np.arange(3))\n",
    "        X = np.ravel(X)\n",
    "        Y = np.ravel(Y)\n",
    "\n",
    "        fig, ax  = plt.subplots(3,3,figsize=(20,15))\n",
    "        for x in range(9):\n",
    "            myim = skimage.io.imread(tosave_folder+'fig5sup/'+cond+'_'+simtype+'_'+str(x)+'.png')\n",
    "            ax[Y[x],X[x]].imshow(myim)\n",
    "            ax[Y[x],X[x]].set_axis_off()\n",
    "        plt.tight_layout(h_pad=-0,w_pad=-10)\n",
    "        plt.show()\n",
    "        fig.savefig(tosave_folder+figname,dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
